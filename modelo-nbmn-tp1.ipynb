{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T21:02:54.504267Z","iopub.execute_input":"2021-09-30T21:02:54.505089Z","iopub.status.idle":"2021-09-30T21:02:54.513422Z","shell.execute_reply.started":"2021-09-30T21:02:54.505046Z","shell.execute_reply":"2021-09-30T21:02:54.512705Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Trabajo Práctico 1\nSe buscó analizar si existe un sesgo en el dataset de snli donde el contenido mismo del texto puede estar delatando si existe una contradicción con respecto a la hipótesis oculta.\n## Carga de Datos\nSe cargaron los datasets correspondientes para observación, ya divididos en datos de entrenamiento, validación y prueba.","metadata":{}},{"cell_type":"code","source":"# Cargo los datos\ndf_train = pd.read_hdf(\"/kaggle/input/sesgos-en-el-dataset-de-snli/train_data.hdf5\")\ndf_valid = pd.read_hdf(\"/kaggle/input/sesgos-en-el-dataset-de-snli/valid_data.hdf5\")\ndf_test = pd.read_hdf(\"/kaggle/input/sesgos-en-el-dataset-de-snli/test_data.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:02:54.514795Z","iopub.execute_input":"2021-09-30T21:02:54.515187Z","iopub.status.idle":"2021-09-30T21:02:59.835780Z","shell.execute_reply.started":"2021-09-30T21:02:54.515153Z","shell.execute_reply":"2021-09-30T21:02:59.835021Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.read_csv(\"/kaggle/input/sesgos-en-el-dataset-de-snli/submission_sample.csv\", index_col=\"pairID\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:02:59.837118Z","iopub.execute_input":"2021-09-30T21:02:59.837573Z","iopub.status.idle":"2021-09-30T21:02:59.862139Z","shell.execute_reply.started":"2021-09-30T21:02:59.837528Z","shell.execute_reply":"2021-09-30T21:02:59.861376Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text_train = df_train[\"text\"].tolist()\nlabels_train = df_train[\"gold_label\"].tolist()\ntext_val = df_valid[\"text\"].tolist()\nlabels_val = df_valid[\"gold_label\"].tolist()\ntext_test = df_test[\"text\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:02:59.863329Z","iopub.execute_input":"2021-09-30T21:02:59.863631Z","iopub.status.idle":"2021-09-30T21:02:59.933341Z","shell.execute_reply.started":"2021-09-30T21:02:59.863594Z","shell.execute_reply":"2021-09-30T21:02:59.932404Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Veamos el balance de clases\nfrom collections import Counter\nCounter(labels_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:02:59.936397Z","iopub.execute_input":"2021-09-30T21:02:59.937016Z","iopub.status.idle":"2021-09-30T21:03:00.015671Z","shell.execute_reply.started":"2021-09-30T21:02:59.936984Z","shell.execute_reply":"2021-09-30T21:03:00.014805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Pre-procesamiento de Texto\n+ NLTK (Natural Language Toolkit)\n  + Lemmatization: reduce a sus significados (ej, quita conjugación verbal)\n  + Stop Words: quita preposiciones (como palabras muy usuales de relleno?)\n  + Stemming: reduce las palabras a su raíz\n  + Filtrado de no palabras","metadata":{}},{"cell_type":"code","source":"# Paquetes de Natural Language Tool Kit\nimport nltk\n#Tokenización (a partir de este se trabajan las otras combinacionies)\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\nlemmatizer = WordNetLemmatizer()\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:00.017033Z","iopub.execute_input":"2021-09-30T21:03:00.017305Z","iopub.status.idle":"2021-09-30T21:03:01.755456Z","shell.execute_reply.started":"2021-09-30T21:03:00.017265Z","shell.execute_reply":"2021-09-30T21:03:01.754611Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Función con la cual también decido cómo pre-procesar\ndef text_filter(dataset, do_lemm, do_stop, do_stem, do_alpha):\n    texts_filtrados = list()\n    for idx in range(len(dataset.text)):\n        if idx%100==0:\n            print(\"\\r Procesados: {}\".format(idx),end=\"\")\n        em = dataset.text[idx]\n        tok = word_tokenize(em)\n        if do_lemm == True:\n            lem = [lemmatizer.lemmatize(x,pos='v') for x in tok]\n        else:\n            lem = tok\n        if do_stop == True:\n            stop = [x for x in lem if x not in stopwords.words('english')]\n        else:\n            stop = lem\n        if do_stem == True:\n            stem = [stemmer.stem(x) for x in stop]\n        else:\n            stem = stop\n        if do_alpha == True:\n            alpha = [x for x in stem if x.isalpha()]\n        else:\n            alpha = stem\n        texts_filtrados.append(\" \".join(alpha))\n    return texts_filtrados","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.756528Z","iopub.execute_input":"2021-09-30T21:03:01.756764Z","iopub.status.idle":"2021-09-30T21:03:01.766230Z","shell.execute_reply.started":"2021-09-30T21:03:01.756735Z","shell.execute_reply":"2021-09-30T21:03:01.765392Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Vectorizadores\n+ Count Vectorizer\n+ TFIDF Vectorizer","metadata":{}},{"cell_type":"code","source":"#Importo los vectorizadores\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.767217Z","iopub.execute_input":"2021-09-30T21:03:01.767398Z","iopub.status.idle":"2021-09-30T21:03:01.778050Z","shell.execute_reply.started":"2021-09-30T21:03:01.767376Z","shell.execute_reply":"2021-09-30T21:03:01.777136Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\ndf_min = 10 # min_df: idem\nn_range = (1,1) # ngram_range: (1,1) default\ncv_cv = CountVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.779082Z","iopub.execute_input":"2021-09-30T21:03:01.779303Z","iopub.status.idle":"2021-09-30T21:03:01.790097Z","shell.execute_reply.started":"2021-09-30T21:03:01.779278Z","shell.execute_reply":"2021-09-30T21:03:01.789231Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_max = 1.0\ndf_min = 10\nn_range = (1,1)\ncv_idf = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.791295Z","iopub.execute_input":"2021-09-30T21:03:01.791648Z","iopub.status.idle":"2021-09-30T21:03:01.800802Z","shell.execute_reply.started":"2021-09-30T21:03:01.791608Z","shell.execute_reply":"2021-09-30T21:03:01.800076Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_cvs(text_train, text_valid, cv):\n    cv_train = cv.fit_transform(text_train)\n    cv_valid = cv.transform(text_valid)\n    return cv_train, cv_valid","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.801821Z","iopub.execute_input":"2021-09-30T21:03:01.802472Z","iopub.status.idle":"2021-09-30T21:03:01.810928Z","shell.execute_reply.started":"2021-09-30T21:03:01.802440Z","shell.execute_reply":"2021-09-30T21:03:01.810380Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Calisificadores\n+ Multinomial Naive-Bayes\n+ Regresión Logística (MLP)","metadata":{}},{"cell_type":"markdown","source":"### Multinomial Naive-Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.811802Z","iopub.execute_input":"2021-09-30T21:03:01.812108Z","iopub.status.idle":"2021-09-30T21:03:01.823910Z","shell.execute_reply.started":"2021-09-30T21:03:01.812084Z","shell.execute_reply":"2021-09-30T21:03:01.823331Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Parámetros del Clasificador\na = 1e-10\nclf_NBMN = MultinomialNB(alpha = a)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.824862Z","iopub.execute_input":"2021-09-30T21:03:01.825214Z","iopub.status.idle":"2021-09-30T21:03:01.832314Z","shell.execute_reply.started":"2021-09-30T21:03:01.825190Z","shell.execute_reply":"2021-09-30T21:03:01.831827Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Multilevel Perceptrons","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n#from tensorflow.keras.models import Sequential\n#from tensorflow.keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:04:57.226082Z","iopub.execute_input":"2021-09-30T21:04:57.226773Z","iopub.status.idle":"2021-09-30T21:04:57.231223Z","shell.execute_reply.started":"2021-09-30T21:04:57.226733Z","shell.execute_reply":"2021-09-30T21:04:57.230573Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(hidden_units, input_shape=(input_dim,), activation='relu'))\nmodel.add(Dense(10, activation='tanh'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\n# Dimm capa entrada: num de vocablos\n# Dimm capa salida: 3","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.920522Z","iopub.status.idle":"2021-09-30T21:03:01.920969Z","shell.execute_reply.started":"2021-09-30T21:03:01.920784Z","shell.execute_reply":"2021-09-30T21:03:01.920801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Métricas\n+ Primaria:\n + asdf\n+ Secundarias:\n + Precision\n + Recall\n + F1-score\n + ROC-AUC","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:06:17.974194Z","iopub.execute_input":"2021-09-30T21:06:17.975101Z","iopub.status.idle":"2021-09-30T21:06:17.979699Z","shell.execute_reply.started":"2021-09-30T21:06:17.975042Z","shell.execute_reply":"2021-09-30T21:06:17.979013Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_scores(clf, X_train, y_train, X_valid, y_valid):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_valid)\n    \n    score_train = clf.score(X_train, y_train)\n    score_valid = clf.score(X_valid, y_valid)\n    return (score_train, score_valid)\n    \ndef get_metrics(clf, X_valid, y_valid):\n    y_pred = clf.predict(X_test)\n    m_conf = metrics.confusion_matrix(y_valid, y_pred)\n    precision = metrics.precision_score(y_valid, y_pred)\n    recall_score = metrics.recall_score(y_valid,y_pred)\n    f1_score = metrics.f1_score(y_valid,y_pred)\n    acc = metrics.accuracy_score(y_valid, y_pred)\n    \n    return score_train, score_valid, m_conf, precision, recall_score, f1_score, acc","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:06:18.886274Z","iopub.execute_input":"2021-09-30T21:06:18.886995Z","iopub.status.idle":"2021-09-30T21:06:18.893541Z","shell.execute_reply.started":"2021-09-30T21:06:18.886963Z","shell.execute_reply":"2021-09-30T21:06:18.892933Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Función que hace todo lo anterior de una\ndef process_data(clf, cv, df_train, df_valid, do_lemm, do_stop, do_stem, do_alpha):\n    print(\"\\n  Filtrando Textos\")\n    texts_train = text_filter(df_train, do_lemm, do_stop, do_stem, do_alpha)\n    texts_valid = text_filter(df_valid, do_lemm, do_stop, do_stem, do_alpha)\n    \n    labels_train = df_train[\"gold_label\"].tolist()\n    labels_valid = df_valid[\"gold_label\"].tolist()\n    \n    print(\"\\nVectorizando\")\n    cv_train, cv_valid = get_cvs(texts_train, texts_valid, cv)\n    \n    print(\"Obteniendo Puntajes\")\n    score_train, score_valid = get_scores(clf, cv_train, labels_train, cv_valid, labels_valid)\n    return (cv_train, cv_valid, score_train, score_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:03:01.924513Z","iopub.status.idle":"2021-09-30T21:03:01.925120Z","shell.execute_reply.started":"2021-09-30T21:03:01.924906Z","shell.execute_reply":"2021-09-30T21:03:01.924926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_raw = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, False, False)\ntest_lemm = process_data(clf_NBMN, cv_cv, df_train, df_valid, True, False, False, False)\ntest_stop = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, True, False, False)\ntest_stem = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, True, False)\ntest_alfa = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, False, True)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:15:25.032924Z","iopub.execute_input":"2021-09-30T19:15:25.033390Z","iopub.status.idle":"2021-09-30T19:36:29.196671Z","shell.execute_reply.started":"2021-09-30T19:15:25.033349Z","shell.execute_reply":"2021-09-30T19:36:29.195592Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(\"Train/Valid:\")\nprint(\"raw:  \",  test_raw[2],\"; \",  test_raw[3])\nprint(\"lemm: \", test_lemm[2],\"; \", test_lemm[3])\nprint(\"stop: \", test_stop[2],\"; \", test_stop[3])\nprint(\"stem: \", test_stem[2],\"; \", test_stem[3])\nprint(\"alfa: \", test_alfa[2],\"; \", test_alfa[3])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T19:36:29.198725Z","iopub.execute_input":"2021-09-30T19:36:29.199004Z","iopub.status.idle":"2021-09-30T19:36:29.208754Z","shell.execute_reply.started":"2021-09-30T19:36:29.198974Z","shell.execute_reply":"2021-09-30T19:36:29.207945Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Observando los resultados de estas pruebas, parece ser que aplicar cualquiera de los filtros de lenguaje natural resulta en una disminusión en la capacidad del modelo de predecir correctamente los resultados deseados. Esto puede deberse a que existe información dentro de cada elemento eliminado que podría llevar a concluir si la frase es contradictoria, neutral o afirmativa.\n\nDebido a esto, se procederá a trabajar con los datos sin aplicar los filtros del paquete NLTK.","metadata":{}},{"cell_type":"code","source":"# Finalmente se trabaja sin filtros\ntext_train_final = text_filter(df_train, True, False, True, False)\ntext_valid_final = text_filter(df_valid, True, False, True, False)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T01:50:02.460506Z","iopub.execute_input":"2021-09-30T01:50:02.460893Z","iopub.status.idle":"2021-09-30T01:53:42.880461Z","shell.execute_reply.started":"2021-09-30T01:50:02.460853Z","shell.execute_reply":"2021-09-30T01:53:42.879537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finalmente se trabaja sin filtros\ntext_train_final = text_train\ntext_valid_final = text_val","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:05:59.483535Z","iopub.execute_input":"2021-09-30T21:05:59.483874Z","iopub.status.idle":"2021-09-30T21:05:59.487872Z","shell.execute_reply.started":"2021-09-30T21:05:59.483839Z","shell.execute_reply":"2021-09-30T21:05:59.486792Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Definido el pre-procesamiento se analizó si se obtienen mejores resultados utilizando el CountVectorizer o TFIDFVectorizer.","metadata":{}},{"cell_type":"code","source":"df_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\ndf_min = 10 # min_df: idem\nn_range = (1,2) # ngram_range: (1,1) default","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:45:06.274656Z","iopub.execute_input":"2021-09-30T21:45:06.275033Z","iopub.status.idle":"2021-09-30T21:45:06.280624Z","shell.execute_reply.started":"2021-09-30T21:45:06.274992Z","shell.execute_reply":"2021-09-30T21:45:06.279594Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cv_cv = CountVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)\ncv_idf = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:45:08.197481Z","iopub.execute_input":"2021-09-30T21:45:08.198184Z","iopub.status.idle":"2021-09-30T21:45:08.435104Z","shell.execute_reply.started":"2021-09-30T21:45:08.198136Z","shell.execute_reply":"2021-09-30T21:45:08.434116Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"cv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv_cv)\ncv_scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\ncv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv_idf)\nidf_scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\n\nprint(cv_scores)\nprint(idf_scores)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T21:45:09.671983Z","iopub.execute_input":"2021-09-30T21:45:09.672282Z","iopub.status.idle":"2021-09-30T21:45:38.482134Z","shell.execute_reply.started":"2021-09-30T21:45:09.672253Z","shell.execute_reply":"2021-09-30T21:45:38.481039Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Bajo las mismas condiciones el TFIDF Vectorizer parece tener un mejor rendimiento a la hora de predecir los resultados correctamente. Por lo tanto las siguientes pruebas se harán con el TFIDF.\n\n","metadata":{}},{"cell_type":"code","source":"# Hago un Sweep para optimizar el min_df\ntrain_scores = list()\nvalid_scores = list()\ndf_mins = range(5,15,1)\nfor i in df_mins:\n    cv = TfidfVectorizer(max_df = df_max, min_df= i, ngram_range = n_range)\n    cv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv)\n    scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\n    train_scores.append(scores[0])\n    valid_scores.append(scores[1])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T22:37:08.361845Z","iopub.execute_input":"2021-09-30T22:37:08.362385Z","iopub.status.idle":"2021-09-30T22:39:38.743319Z","shell.execute_reply.started":"2021-09-30T22:37:08.362334Z","shell.execute_reply":"2021-09-30T22:39:38.742370Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(df_mins,train_scores)\nplt.plot(df_mins,valid_scores)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T22:39:38.745092Z","iopub.execute_input":"2021-09-30T22:39:38.745379Z","iopub.status.idle":"2021-09-30T22:39:38.972156Z","shell.execute_reply.started":"2021-09-30T22:39:38.745348Z","shell.execute_reply":"2021-09-30T22:39:38.971180Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"Con un min_df = 8 se obtuvo el score_valid más alto.","metadata":{}},{"cell_type":"code","source":"# Puedo hacer el sweep para ver qué onda si cambio max_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Algo pasa más arriba de acá","metadata":{}},{"cell_type":"code","source":"clf.fit(cv_train, labels_train)\nlabels_pred = clf.predict(cv_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Veamos cómo funciona el clasificador para train\nclf.score(cv_train, labels_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Veamos cómo funciona el clasificador para valid\nclf.score(cv_valid, labels_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_test = cv.transform(text_test_final)\nget_metrics(clf, cv_test, labels_test)\n# test_labels = clf.predict(cv_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelo Final","metadata":{}},{"cell_type":"code","source":"# Parámetros de Pre-procesamiento (sin procesamiento)\ntext_train_final = text_train\ntext_valid_final = text_val\n\n# Parámetros del Count Vectorizer\ndf_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\ndf_min = 8 # min_df: obtenido de una curva\nn_range = (1,2) # ngram_range: (1,1) default\n\ncv = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)\n\n# Parámetros del Clasificador\na = 1e-4\nclf = MultinomialNB(alpha = a)\n\ncv_train = cv.fit_transform(text_train_final)\nclf.fit(cv_train, labels_train)\n\ncv_test = cv.transform(text_test)\ntest_labels = clf.predict(cv_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:10:56.758071Z","iopub.execute_input":"2021-09-30T23:10:56.758334Z","iopub.status.idle":"2021-09-30T23:11:11.004797Z","shell.execute_reply.started":"2021-09-30T23:10:56.758307Z","shell.execute_reply":"2021-09-30T23:11:11.004015Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Métricas del modelo final","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Para armar Submission\nUna vez elegido el grado de pre-procesamiento, el vectorizador y el clasificador, lo aplico sobre el el test.\n+ Preprocesamiento: Lemmatization, Stemming y No-Palabras\n+ Vectorizador: TFIDF\n+ Clasificador: Multinomial Naive-Bayes","metadata":{}},{"cell_type":"code","source":"#Armo el submission.csv\ndf_test = pd.DataFrame(data=test_labels, columns=[\"pred_labels\"],)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:11:16.015374Z","iopub.execute_input":"2021-09-30T23:11:16.015681Z","iopub.status.idle":"2021-09-30T23:11:16.022765Z","shell.execute_reply.started":"2021-09-30T23:11:16.015647Z","shell.execute_reply":"2021-09-30T23:11:16.021643Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:11:19.911878Z","iopub.execute_input":"2021-09-30T23:11:19.912203Z","iopub.status.idle":"2021-09-30T23:11:19.927182Z","shell.execute_reply.started":"2021-09-30T23:11:19.912173Z","shell.execute_reply":"2021-09-30T23:11:19.926050Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"df_test.index.names = [\"pairID\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:11:30.239675Z","iopub.execute_input":"2021-09-30T23:11:30.239971Z","iopub.status.idle":"2021-09-30T23:11:30.244073Z","shell.execute_reply.started":"2021-09-30T23:11:30.239919Z","shell.execute_reply":"2021-09-30T23:11:30.243080Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:11:32.943772Z","iopub.execute_input":"2021-09-30T23:11:32.944424Z","iopub.status.idle":"2021-09-30T23:11:32.957075Z","shell.execute_reply.started":"2021-09-30T23:11:32.944384Z","shell.execute_reply":"2021-09-30T23:11:32.956462Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df_test.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-30T23:11:39.728868Z","iopub.execute_input":"2021-09-30T23:11:39.729730Z","iopub.status.idle":"2021-09-30T23:11:39.764287Z","shell.execute_reply.started":"2021-09-30T23:11:39.729688Z","shell.execute_reply":"2021-09-30T23:11:39.763581Z"},"trusted":true},"execution_count":65,"outputs":[]}]}